"""
[ë³´ì•ˆ íŒ¨ì¹˜ ì™„ë£Œ] í™•ì¥ ê°€ëŠ¥í•œ í¬ë¡¤ë§ API ì„œë²„ v2.1
- ë³´ì•ˆ: API Key ê°•ì œ, ê´€ë¦¬ì ID ê²€ì¦ ì¶”ê°€
- ê¸°ëŠ¥: ë´‡ ë°©ì§€, í…”ë ˆê·¸ë¨ ì œì–´
"""

from flask import Flask, jsonify, request
import requests
from bs4 import BeautifulSoup
import os
import time
import random
from datetime import datetime
from abc import ABC, abstractmethod

app = Flask(__name__)

# ============================================================
# ğŸ“Œ ì„¤ì • (ë³´ì•ˆ ê°•í™”: ê¸°ë³¸ê°’ ì‚­ì œ)
# ============================================================

# í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ì„œë²„ê°€ ì¼œì§€ì§€ ì•Šê²Œ ê°•ì œí•¨ (ë³´ì•ˆ ì‚¬ê³  ë°©ì§€)
try:
    API_SECRET_KEY = os.environ["API_SECRET_KEY"]
    TELEGRAM_BOT_TOKEN = os.environ["TELEGRAM_BOT_TOKEN"]
    ADMIN_CHAT_ID = os.environ["ADMIN_CHAT_ID"]
except KeyError as e:
    print(f"âŒ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("í•„ìˆ˜: API_SECRET_KEY, TELEGRAM_BOT_TOKEN, ADMIN_CHAT_ID")
    exit(1)

# User-Agent ë¡œí…Œì´ì…˜ (5ê°œ ìœ ì§€)
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15"
]

# ê°¤ëŸ¬ë¦¬ ì˜êµ¬ ì €ì¥ íŒŒì¼ (ì„œë²„ ì¬ì‹œì‘í•´ë„ ìœ ì§€)
import json
GALLERIES_FILE = "/tmp/galleries.json"

def load_galleries():
    """ì €ì¥ëœ ê°¤ëŸ¬ë¦¬ ëª©ë¡ ë¡œë“œ"""
    try:
        with open(GALLERIES_FILE, 'r') as f:
            return json.load(f)
    except:
        # í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’
        default = os.environ.get("DEFAULT_GALLERIES", "thesingularity")
        return default.split(",")

def save_galleries(galleries):
    """ê°¤ëŸ¬ë¦¬ ëª©ë¡ ì €ì¥"""
    try:
        with open(GALLERIES_FILE, 'w') as f:
            json.dump(galleries, f)
    except:
        pass

CRAWLER_STATE = {
    "enabled": True,
    "galleries": load_galleries()
}

# ============================================================
# ğŸ“Œ ê¸°ë³¸ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤
# ============================================================

class BaseCrawler(ABC):
    def __init__(self):
        self.session = requests.Session()
    
    def get_headers(self):
        return {
            "User-Agent": random.choice(USER_AGENTS),
            "Accept": "text/html,application/xhtml+xml,*/*;q=0.8",
            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "Upgrade-Insecure-Requests": "1"
        }
    
    def random_delay(self):
        time.sleep(random.uniform(1, 2))
    
    @abstractmethod
    def get_list_url(self, gallery_id, page, recommend_only): pass
    @abstractmethod
    def parse_list(self, html): pass
    @abstractmethod
    def get_detail_url(self, post_id, gallery_id): pass
    @abstractmethod
    def parse_detail(self, html): pass
    
    def crawl_list(self, gallery_id, page=1, recommend_only=True):
        try:
            url = self.get_list_url(gallery_id, page, recommend_only)
            self.random_delay()
            response = self.session.get(url, headers=self.get_headers(), timeout=10)
            response.raise_for_status()
            posts = self.parse_list(response.text)
            return {"success": True, "count": len(posts), "posts": posts}
        except Exception as e:
            return {"success": False, "error": str(e), "posts": []}
    
    def crawl_detail(self, post_id, gallery_id):
        try:
            url = self.get_detail_url(post_id, gallery_id)
            self.random_delay()
            response = self.session.get(url, headers=self.get_headers(), timeout=10)
            response.raise_for_status()
            detail = self.parse_detail(response.text)
            detail["success"] = True
            return detail
        except Exception as e:
            return {"success": False, "error": str(e)}

# ============================================================
# ğŸ“Œ ë””ì‹œì¸ì‚¬ì´ë“œ í¬ë¡¤ëŸ¬
# ============================================================

class DCInsideCrawler(BaseCrawler):
    def get_list_url(self, gallery_id, page, recommend_only):
        base = f"https://gall.dcinside.com/mgallery/board/lists/?id={gallery_id}&page={page}"
        if recommend_only:
            base += "&exception_mode=recommend"
        return base
    
    def get_detail_url(self, post_id, gallery_id):
        return f"https://gall.dcinside.com/mgallery/board/view/?id={gallery_id}&no={post_id}"
    
    def parse_list(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        posts = []
        for row in soup.select('tr.ub-content'):
            try:
                post_id = row.get('data-no')
                if not post_id:
                    continue
                
                title_elem = row.select_one('td.gall_tit a')
                if not title_elem:
                    continue
                
                title = title_elem.get_text(strip=True)
                link = title_elem.get('href', '')
                if link.startswith('/'):
                    link = "https://gall.dcinside.com" + link
                
                date_elem = row.select_one('td.gall_date')
                date = date_elem.get('title', '') if date_elem else ''
                
                writer_elem = row.select_one('td.gall_writer')
                writer = writer_elem.get('data-nick', '') if writer_elem else ''
                
                # viewCount, recommend ìœ ì§€
                count_elem = row.select_one('td.gall_count')
                view_count = count_elem.get_text(strip=True) if count_elem else ''
                
                recommend_elem = row.select_one('td.gall_recommend')
                recommend = recommend_elem.get_text(strip=True) if recommend_elem else ''
                
                posts.append({
                    'id': post_id,
                    'title': title,
                    'link': link,
                    'date': date,
                    'writer': writer,
                    'viewCount': view_count,
                    'recommend': recommend
                })
            except:
                continue
        return posts
    
    def parse_detail(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        content_elem = soup.select_one('div.write_div')
        content = content_elem.get_text('\n', strip=True)[:5000] if content_elem else ""
        images = []
        if content_elem:
            for img in content_elem.select('img'):
                src = img.get('src', '')
                if 'dcimg' in src:
                    if src.startswith('//'):
                        src = 'https:' + src
                    images.append(src)
        return {"content": content, "images": images[:20]}

CRAWLERS = {"dcinside": DCInsideCrawler}

# ============================================================
# ğŸ“Œ í—¬í¼ í•¨ìˆ˜
# ============================================================

def verify_api_key():
    key = request.headers.get("X-API-Key") or request.args.get("api_key")
    return key and key == API_SECRET_KEY

def send_telegram(text, reply_markup=None):
    try:
        payload = {"chat_id": ADMIN_CHAT_ID, "text": text, "parse_mode": "HTML"}
        if reply_markup:
            payload["reply_markup"] = reply_markup
        requests.post(
            f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage",
            json=payload,
            timeout=10
        )
    except:
        pass

def get_main_menu():
    """ë©”ì¸ ë©”ë‰´ ì¸ë¼ì¸ í‚¤ë³´ë“œ"""
    return {
        "inline_keyboard": [
            [{"text": "ğŸ“Š ìƒíƒœ", "callback_data": "status"}, 
             {"text": "ğŸ“ ê°¤ëŸ¬ë¦¬", "callback_data": "galleries"}],
            [{"text": "â¸ï¸ ì •ì§€", "callback_data": "pause"}, 
             {"text": "â–¶ï¸ ì¬ê°œ", "callback_data": "resume"}],
            [{"text": "â“ ë„ì›€ë§", "callback_data": "help"}]
        ]
    }

def answer_callback(callback_id, text=""):
    """ì½œë°± ì¿¼ë¦¬ ì‘ë‹µ"""
    try:
        requests.post(
            f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/answerCallbackQuery",
            json={"callback_query_id": callback_id, "text": text},
            timeout=10
        )
    except:
        pass

# ============================================================
# ğŸ“Œ API ì—”ë“œí¬ì¸íŠ¸
# ============================================================

@app.route('/')
def home():
    return jsonify({
        'status': 'ok',
        'message': 'Secure Crawler v2.1',
        'supported_sites': list(CRAWLERS.keys())
    })

@app.route('/health')
def health():
    return jsonify({'status': 'healthy', 'timestamp': datetime.now().isoformat()})

@app.route('/status')
def status():
    if not verify_api_key():
        return jsonify({'error': 'Unauthorized'}), 401
    return jsonify({
        'enabled': CRAWLER_STATE['enabled'],
        'galleries': CRAWLER_STATE['galleries']
    })

@app.route('/crawl')
def crawl():
    if not verify_api_key():
        return jsonify({'error': 'Unauthorized'}), 401
    if not CRAWLER_STATE['enabled']:
        return jsonify({'success': False, 'error': 'Paused'})
    
    site = request.args.get('site', 'dcinside')
    gallery_id = request.args.get('gallery_id', 'thesingularity')
    page = request.args.get('page', 1, type=int)
    
    if site not in CRAWLERS:
        return jsonify({'success': False, 'error': 'Unknown site'})
    
    result = CRAWLERS[site]().crawl_list(gallery_id, page, True)
    result['site'] = site
    result['gallery_id'] = gallery_id
    return jsonify(result)

@app.route('/crawl-detail')
def crawl_detail():
    if not verify_api_key():
        return jsonify({'error': 'Unauthorized'}), 401
    
    site = request.args.get('site', 'dcinside')
    gallery_id = request.args.get('gallery_id')
    post_id = request.args.get('post_id')
    
    if not post_id or not gallery_id:
        return jsonify({'success': False, 'error': 'post_idì™€ gallery_id í•„ìš”'})
    
    if site not in CRAWLERS:
        return jsonify({'success': False, 'error': 'Unknown site'})
    
    return jsonify(CRAWLERS[site]().crawl_detail(post_id, gallery_id))

# ============================================================
# ğŸ“Œ í…”ë ˆê·¸ë¨ Webhook (ê´€ë¦¬ì ì „ìš©)
# ============================================================

@app.route('/webhook', methods=['POST'])
def webhook():
    try:
        data = request.get_json()
        
        # ì½œë°± ì¿¼ë¦¬ ì²˜ë¦¬ (ë²„íŠ¼ í´ë¦­)
        callback = data.get('callback_query')
        if callback:
            callback_id = callback.get('id')
            chat_id = str(callback.get('from', {}).get('id', ''))
            action = callback.get('data', '')
            
            if chat_id != str(ADMIN_CHAT_ID):
                return jsonify({'ok': True})
            
            answer_callback(callback_id)
            
            if action == 'status':
                status_text = f"ğŸ¤– <b>í¬ë¡¤ëŸ¬ ìƒíƒœ</b>\n\n"
                status_text += f"ìƒíƒœ: {'âœ… ë™ì‘ì¤‘' if CRAWLER_STATE['enabled'] else 'â¸ï¸ ì •ì§€'}\n"
                status_text += f"ê°¤ëŸ¬ë¦¬: {', '.join(CRAWLER_STATE['galleries'])}"
                send_telegram(status_text, get_main_menu())
            elif action == 'galleries':
                gall_text = "ğŸ“ <b>ê°¤ëŸ¬ë¦¬ ëª©ë¡</b>\n\n"
                for i, g in enumerate(CRAWLER_STATE['galleries'], 1):
                    gall_text += f"{i}. {g}\n"
                send_telegram(gall_text, get_main_menu())
            elif action == 'pause':
                CRAWLER_STATE['enabled'] = False
                send_telegram("â¸ï¸ í¬ë¡¤ëŸ¬ ì •ì§€ë¨", get_main_menu())
            elif action == 'resume':
                CRAWLER_STATE['enabled'] = True
                send_telegram("â–¶ï¸ í¬ë¡¤ëŸ¬ ì¬ê°œë¨", get_main_menu())
            elif action == 'help':
                help_text = "ğŸ¤– <b>ëª…ë ¹ì–´</b>\n\n"
                help_text += "/menu - ë²„íŠ¼ ë©”ë‰´\n"
                help_text += "/add [ID] - ê°¤ëŸ¬ë¦¬ ì¶”ê°€\n"
                help_text += "/remove [ID] - ê°¤ëŸ¬ë¦¬ ì œê±°"
                send_telegram(help_text, get_main_menu())
            
            return jsonify({'ok': True})
        
        # ì¼ë°˜ ë©”ì‹œì§€ ì²˜ë¦¬
        msg = data.get('message', {})
        chat_id = str(msg.get('chat', {}).get('id', ''))
        text = msg.get('text', '').strip()
        
        if chat_id != str(ADMIN_CHAT_ID):
            return jsonify({'ok': True})
        
        if text == '/start' or text == '/menu':
            send_telegram("ğŸ¤– <b>í¬ë¡¤ëŸ¬ ì œì–´íŒ</b>\n\në²„íŠ¼ì„ ëˆŒëŸ¬ ì œì–´í•˜ì„¸ìš”:", get_main_menu())
        
        elif text == '/status':
            status_text = f"ğŸ¤– <b>í¬ë¡¤ëŸ¬ ìƒíƒœ</b>\n\n"
            status_text += f"ìƒíƒœ: {'âœ… ë™ì‘ì¤‘' if CRAWLER_STATE['enabled'] else 'â¸ï¸ ì •ì§€'}\n"
            status_text += f"ê°¤ëŸ¬ë¦¬: {', '.join(CRAWLER_STATE['galleries'])}"
            send_telegram(status_text, get_main_menu())
        
        elif text == '/galleries':
            gall_text = "ğŸ“ <b>ê°¤ëŸ¬ë¦¬ ëª©ë¡</b>\n\n"
            for i, g in enumerate(CRAWLER_STATE['galleries'], 1):
                gall_text += f"{i}. {g}\n"
            send_telegram(gall_text, get_main_menu())
        
        elif text.startswith('/add '):
            gallery_id = text[5:].strip()
            if gallery_id and gallery_id not in CRAWLER_STATE['galleries']:
                CRAWLER_STATE['galleries'].append(gallery_id)
                save_galleries(CRAWLER_STATE['galleries'])  # ì €ì¥
                send_telegram(f"âœ… ê°¤ëŸ¬ë¦¬ ì¶”ê°€ë¨: {gallery_id}", get_main_menu())
            else:
                send_telegram("âŒ ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ì˜ëª»ëœ ID", get_main_menu())
        
        elif text.startswith('/remove '):
            gallery_id = text[8:].strip()
            if gallery_id in CRAWLER_STATE['galleries']:
                CRAWLER_STATE['galleries'].remove(gallery_id)
                save_galleries(CRAWLER_STATE['galleries'])  # ì €ì¥
                send_telegram(f"âœ… ê°¤ëŸ¬ë¦¬ ì œê±°ë¨: {gallery_id}", get_main_menu())
            else:
                send_telegram("âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê°¤ëŸ¬ë¦¬", get_main_menu())
        
        elif text == '/pause':
            CRAWLER_STATE['enabled'] = False
            send_telegram("â¸ï¸ í¬ë¡¤ëŸ¬ ì •ì§€ë¨", get_main_menu())
        
        elif text == '/resume':
            CRAWLER_STATE['enabled'] = True
            send_telegram("â–¶ï¸ í¬ë¡¤ëŸ¬ ì¬ê°œë¨", get_main_menu())
        
        elif text == '/crawl':
            # ìˆ˜ë™ í¬ë¡¤ë§ íŠ¸ë¦¬ê±° (GASê°€ /trigger ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ì•ˆë‚´)
            send_telegram("ğŸ”„ ìˆ˜ë™ í¬ë¡¤ë§ì„ ì‹œì‘í•˜ë ¤ë©´ GASì—ì„œ testCrawling()ì„ ì‹¤í–‰í•˜ì„¸ìš”.\n\në˜ëŠ” Apps Scriptì—ì„œ ì§ì ‘ ì‹¤í–‰!")
        
        elif text == '/help':
            help_text = "ğŸ¤– <b>ëª…ë ¹ì–´</b>\n\n"
            help_text += "/menu - ë²„íŠ¼ ë©”ë‰´\n"
            help_text += "/add [ID] - ê°¤ëŸ¬ë¦¬ ì¶”ê°€\n"
            help_text += "/remove [ID] - ê°¤ëŸ¬ë¦¬ ì œê±°\n"
            help_text += "/crawl - ìˆ˜ë™ í¬ë¡¤ë§ ì•ˆë‚´"
            send_telegram(help_text, get_main_menu())
        
        return jsonify({'ok': True})
    except:
        return jsonify({'ok': True})

# ============================================================
# ğŸ“Œ ì‹¤í–‰
# ============================================================

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
